# ğŸš€ Event Stream System

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
[![Django](https://img.shields.io/badge/Django-4.2+-green.svg)](https://djangoproject.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://postgresql.org)
[![Async](https://img.shields.io/badge/Async-Supported-orange.svg)](https://docs.python.org/3/library/asyncio.html)

The Event Stream system provides real-time event processing capabilities for Plane, enabling asynchronous handling of entity changes through an outbox pattern with PostgreSQL triggers and polling mechanisms.

## ğŸ“Š Performance Overview

| Metric                 | Typical Value    | Optimized Value    |
| ---------------------- | ---------------- | ------------------ |
| **Throughput**         | 1,000 events/sec | 5,000+ events/sec  |
| **Latency**            | < 250ms          | < 100ms            |
| **Memory Usage**       | 200-500MB        | Configurable limit |
| **CPU Usage**          | 5-15%            | Variable with load |
| **Batch Size**         | 250 events       | Tunable (50-1000)  |
| **Concurrent Pollers** | 1                | Up to 10+          |

## ğŸ“‹ Table of Contents

- [ğŸ—ï¸ Architecture Overview](#ï¸-architecture-overview)
- [ğŸ”§ Components](#-components)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸš€ Usage](#-usage)
- [ğŸ’» Commands](#-commands)
- [ğŸ¯ Event Handlers](#-event-handlers)
- [ğŸ§  Memory Management](#-memory-management)
- [ğŸ‘¨â€ğŸ’» Development](#-development)
- [ğŸ” Troubleshooting](#-troubleshooting)
- [ğŸ“ˆ Performance Tuning](#-performance-tuning)
- [ğŸ“Š Monitoring & Metrics](#-monitoring--metrics)

## ğŸ—ï¸ Architecture Overview

The event stream system implements a reliable outbox pattern with the following flow:

1. **ğŸ—„ï¸ Database Triggers**: PostgreSQL triggers automatically capture entity changes (INSERT/UPDATE/DELETE) and write events to the `outbox` table
2. **ğŸ”„ Event Polling**: Async pollers fetch unprocessed events from the outbox table in batches
3. **âš¡ Event Processing**: Registered handlers process events with full entity data
4. **âœ… Completion Tracking**: Successfully processed events are marked as `processed_at`

### ğŸ¯ Key Benefits

- **ğŸ”’ Reliability**: Transactional consistency ensures no events are lost
- **âš¡ Performance**: Batch processing and efficient querying minimize database load
- **ğŸ§  Memory Safety**: Built-in memory monitoring and automatic restarts prevent memory leaks
- **ğŸ“ˆ Scalability**: Multiple pollers can run concurrently with competitive processing
- **ğŸ”§ Flexibility**: Pluggable handler system allows custom event processing logic

## ğŸ”§ Components

### 1. ğŸ—„ï¸ Models

#### `Outbox` (`models/outbox.py`)

Central event storage table with the following schema:

```python
class Outbox(models.Model):
    id = models.BigAutoField(primary_key=True)           # Unique identifier
    event_id = models.UUIDField(default=uuid4)           # Event UUID
    event_type = models.CharField(max_length=255)        # e.g., "issue.created"
    entity_type = models.CharField(max_length=255)       # e.g., "issue"
    entity_id = models.UUIDField()                       # Entity UUID
    payload = models.JSONField()                         # Full event data
    processed_at = models.DateTimeField(null=True)       # Processing timestamp
    created_at = models.DateTimeField(default=now)       # Creation timestamp
```

**ğŸ“Š Indexes:**

- `outbox_unprocessed_idx`: Optimized for finding unprocessed events
- `outbox_processed_idx`: Optimized for analytics on processed events

#### ğŸ”„ Entity Proxy Models

- `IssueProxy` (`models/issue.py`): Handles issue lifecycle events
- `CycleIssueProxy` (`models/cycle.py`): Handles cycle-issue relationship events
- Additional proxy models for other entities

### 2. ğŸš€ Outbox Poller

#### `OutboxPoller` (`management/commands/outbox_poller.py`)

Async poller that processes events from the outbox table:

```python
class OutboxPoller:
    def __init__(self, batch_size, interval_min, interval_max,
                 memory_limit_mb, memory_check_interval):
        # Configurable processing parameters
        # Handler registration system
        # Memory monitoring
```

**ğŸš€ Key Features:**

- Adaptive polling intervals (backs off when no events)
- Batch processing with `FOR UPDATE SKIP LOCKED`
- Memory monitoring with automatic restarts
- Transactional safety

#### ğŸ”Œ `DatabaseConnection` (`management/commands/outbox_poller.py`)

Async database connection manager:

```python
class DatabaseConnection:
    async def fetch_and_lock_rows(self, batch_size) -> List[tuple]:
        # Fetch and lock events atomically

    async def mark_processed(self, ids: List[int]) -> bool:
        # Mark events as processed
```

### 3. ğŸ­ Production Service

#### `OutboxEventService` (`service.py`)

Production-ready service wrapper:

```python
class OutboxEventService:
    def start(self):
        # Signal handling for graceful shutdown
        # Handler registration
        # Service lifecycle management
```

## âš™ï¸ Configuration

### ğŸŒ Environment Variables

```bash
# Outbox Poller Configuration
OUTBOX_POLLER_BATCH_SIZE=250                    # Events per batch
OUTBOX_POLLER_INTERVAL_MIN=0.25                 # Min polling interval (seconds)
OUTBOX_POLLER_INTERVAL_MAX=2.0                  # Max polling interval (seconds)
OUTBOX_POLLER_MEMORY_LIMIT_MB=500               # Memory limit (MB)
OUTBOX_POLLER_MEMORY_CHECK_INTERVAL=30          # Memory check interval (seconds)
```

### âš™ï¸ Django Settings

Add to `INSTALLED_APPS`:

```python
INSTALLED_APPS = [
    # ... other apps
    'plane.event_stream',
]
```

### ğŸ—„ï¸ Database Configuration

Ensure your PostgreSQL database supports:

- `gen_random_uuid()` function (requires `pgcrypto` extension)
- Row-level locking (`FOR UPDATE SKIP LOCKED`)

## ğŸš€ Usage

### ğŸ”„ Running the Outbox Poller

```bash
# Run with default settings
python manage.py outbox_poller

# Run with custom settings
python manage.py outbox_poller \
    --batch-size 100 \
    --interval-min 0.5 \
    --interval-max 5.0 \
    --memory-limit 1024 \
    --memory-check-interval 60
```

### ğŸ­ Production Service

```python
# service.py
from plane.event_stream.service import main

if __name__ == "__main__":
    main()
```

## ğŸ’» Commands

### ğŸ”„ `outbox_poller`

Async outbox poller that processes events in batches.

**Arguments:**

- `--batch-size`: Number of events to process per batch (default: 250)
- `--interval-min`: Minimum polling interval in seconds (default: 0.25)
- `--interval-max`: Maximum polling interval in seconds (default: 2.0)
- `--memory-limit`: Memory limit in MB before restart (default: 500)
- `--memory-check-interval`: Memory check interval in seconds (default: 30)

**Example:**

```bash
python manage.py outbox_poller --batch-size 500 --memory-limit 1024
```

## ğŸ¯ Event Handlers

### ğŸ“ Registering Handlers

```python
# For outbox poller
poller = OutboxPoller(...)
poller.add_handler(my_event_handler)
```

### ğŸ”§ Handler Function Signature

```python
def my_event_handler(event_data: Dict[str, Any]) -> None:
    """
    Process an event from the outbox.

    Args:
        event_data: Dictionary containing:
            - id: Event ID (int)
            - event_id: Event UUID (str)
            - event_type: Event type (str)
            - entity_type: Entity type (str)
            - entity_id: Entity UUID (str)
            - payload: Event payload (dict)
            - processed_at: Processing timestamp
            - created_at: Creation timestamp
    """
    event_type = event_data["event_type"]
    payload = event_data["payload"]

    # Process the event
    if event_type == "issue.created":
        handle_new_issue(payload)
    elif event_type == "issue.updated":
        handle_issue_update(payload)
```

### âš¡ Async Handlers

Both sync and async handlers are supported:

```python
async def async_event_handler(event_data: Dict[str, Any]) -> None:
    """Async event handler for non-blocking processing."""
    await send_webhook(event_data)
    await update_search_index(event_data)
```

### ğŸ“ Example Handlers

#### ğŸ†• Issue Created Handler

```python
def handle_issue_created(event_data: Dict[str, Any]):
    payload = event_data["payload"]
    issue_data = payload["data"]

    # Send webhook notification
    send_webhook("issue_created", issue_data)

    # Update search index
    update_search_index("issue", issue_data)

    # Send notifications to assignees
    notify_assignees(issue_data.get("assignees", []))
```

#### ğŸ”„ Issue Updated Handler

```python
def handle_issue_updated(event_data: Dict[str, Any]):
    payload = event_data["payload"]
    issue_data = payload["data"]
    previous_data = payload.get("previous_attributes", {})

    # Check what changed
    if "state_id" in previous_data:
        handle_state_change(issue_data, previous_data)

    if "assignees" in previous_data:
        handle_assignee_change(issue_data, previous_data)
```

## ğŸ§  Memory Management

The event stream system includes comprehensive memory management to prevent memory leaks and ensure long-running stability.

### ğŸ“Š Memory Monitoring

The outbox poller monitors memory usage:

```python
class MemoryMonitor:
    def __init__(self, memory_limit_mb: int, check_interval: int):
        # Track memory usage with psutil
        # Automatic restart when limits exceeded
```

### ğŸ”„ Automatic Restarts

When memory limits are exceeded:

1. Current processing completes
2. Resources are cleaned up
3. Process restarts with fresh memory
4. Event processing resumes

### ğŸ’¡ Best Practices

1. **Set appropriate memory limits** based on your environment
2. **Monitor restart frequency** - frequent restarts may indicate issues
3. **Use batch processing** to minimize memory accumulation
4. **Clean up resources** in event handlers

## ğŸ‘¨â€ğŸ’» Development

### ğŸ› ï¸ Setting Up Development Environment

1. **Install dependencies**:

```bash
pip install psycopg[async] psutil
```

2. **Run migrations**:

```bash
python manage.py migrate event_stream
```

3. **Set up database triggers**:

```bash
python manage.py migrate
```

### ğŸ§ª Testing Event Generation

Create test events manually:

```python
from plane.event_stream.models import Outbox

# Create a test event
Outbox.objects.create(
    event_type="test.event",
    entity_type="test",
    entity_id="123e4567-e89b-12d3-a456-426614174000",
    payload={"message": "Hello, World!"}
)
```

### ğŸ†• Custom Event Types

Add new event types by:

1. **Creating proxy models** with appropriate triggers
2. **Registering event handlers** for the new event types
3. **Testing event generation** and processing

## ğŸ” Troubleshooting

### âŒ Common Issues

#### ğŸš« No Events Being Processed

**Symptoms**: Poller runs but no events are processed

**Diagnosis**:

```sql
-- Check for unprocessed events
SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL;

-- Check recent events
SELECT * FROM outbox ORDER BY created_at DESC LIMIT 10;
```

**Solutions**:

- Verify database triggers are installed
- Check handler registration
- Review error logs for handler exceptions

#### ğŸ§  Memory Restarts Too Frequent

**Symptoms**: Process restarts every few minutes

**Diagnosis**:

- Check memory limit settings
- Monitor actual memory usage
- Review handler efficiency

**Solutions**:

- Increase memory limits
- Optimize handler memory usage
- Reduce batch sizes
- Check for memory leaks in handlers

#### ğŸ”Œ Database Connection Issues

**Symptoms**: Connection errors or timeouts

**Solutions**:

- Verify database settings
- Check connection pool configuration
- Review PostgreSQL logs
- Ensure `pgcrypto` extension is installed

#### ğŸ”„ Events Being Processed Multiple Times

**Symptoms**: Duplicate event processing

**Diagnosis**:

- Check database row locking
- Verify transaction boundaries

**Solutions**:

- Ensure proper use of `FOR UPDATE SKIP LOCKED`
- Check for handler exceptions
- Review transaction boundaries

## ğŸ“ˆ Performance Tuning

### ğŸš€ Throughput Optimization

#### Batch Size Tuning

```bash
# Low latency (real-time processing)
python manage.py outbox_poller --batch-size 50 --interval-min 0.1

# High throughput (batch processing)
python manage.py outbox_poller --batch-size 1000 --interval-min 1.0

# Balanced (recommended for most use cases)
python manage.py outbox_poller --batch-size 250 --interval-min 0.25
```

#### Concurrent Processing

```bash
# Run multiple pollers for horizontal scaling
# Terminal 1
python manage.py outbox_poller --batch-size 200

# Terminal 2
python manage.py outbox_poller --batch-size 200

# Terminal 3
python manage.py outbox_poller --batch-size 200
```

### ğŸ¯ Performance Benchmarks

| Configuration                  | Events/sec | Memory (MB) | CPU (%) | Latency (ms) |
| ------------------------------ | ---------- | ----------- | ------- | ------------ |
| **Single Poller (batch=50)**   | 500        | 150         | 8       | 100          |
| **Single Poller (batch=250)**  | 1,200      | 200         | 12      | 200          |
| **Single Poller (batch=1000)** | 2,500      | 350         | 18      | 400          |
| **3 Pollers (batch=250 each)** | 3,000      | 600         | 30      | 250          |
| **5 Pollers (batch=200 each)** | 4,500      | 800         | 45      | 300          |

### âš¡ Database Optimization

#### Index Optimization

```sql
-- Monitor index usage
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE tablename = 'outbox'
ORDER BY idx_scan DESC;

-- Monitor table statistics
SELECT
    seq_scan,
    seq_tup_read,
    idx_scan,
    idx_tup_fetch,
    n_tup_ins,
    n_tup_upd,
    n_tup_del
FROM pg_stat_user_tables
WHERE relname = 'outbox';
```

#### Table Maintenance

```sql
-- Regular cleanup of processed events (run daily)
DELETE FROM outbox
WHERE processed_at < NOW() - INTERVAL '7 days';

-- Vacuum and analyze for performance
VACUUM ANALYZE outbox;

-- Monitor table size
SELECT
    pg_size_pretty(pg_total_relation_size('outbox')) as total_size,
    pg_size_pretty(pg_relation_size('outbox')) as table_size,
    pg_size_pretty(pg_indexes_size('outbox')) as index_size;
```

## ğŸ“Š Monitoring & Metrics

### ğŸ“ˆ Key Performance Indicators (KPIs)

#### Real-time Metrics

```python
# Add to your monitoring system
METRICS = {
    'event_processing_rate': 'events_per_second',
    'queue_depth': 'unprocessed_events_count',
    'memory_usage': 'memory_mb',
    'cpu_usage': 'cpu_percentage',
    'error_rate': 'errors_per_minute',
    'restart_frequency': 'restarts_per_hour',
    'average_latency': 'processing_time_ms'
}
```

#### Health Check Endpoint

```python
# Add to your Django views
def event_stream_health(request):
    unprocessed_count = Outbox.objects.filter(processed_at__isnull=True).count()
    last_processed = Outbox.objects.filter(
        processed_at__isnull=False
    ).order_by('-processed_at').first()

    health_status = {
        'status': 'healthy' if unprocessed_count < 1000 else 'warning',
        'unprocessed_events': unprocessed_count,
        'last_processed_at': last_processed.processed_at if last_processed else None,
        'queue_health': 'ok' if unprocessed_count < 5000 else 'critical'
    }

    return JsonResponse(health_status)
```

### ğŸ“Š Monitoring

#### ğŸ“Š Key Metrics to Monitor

1. **âš¡ Event Processing Rate**: Events processed per second
2. **ğŸ§  Memory Usage**: Current and peak memory consumption
3. **ğŸ”„ Restart Frequency**: How often processes restart
4. **âŒ Error Rate**: Handler failure percentage
5. **ğŸ“¦ Queue Depth**: Number of unprocessed events
6. **â±ï¸ Processing Latency**: Time from event creation to processing
7. **ğŸ”’ Lock Contention**: Database lock wait times

#### ğŸ“Š Database Queries for Monitoring

```sql
-- Unprocessed events by type
SELECT event_type, COUNT(*)
FROM outbox
WHERE processed_at IS NULL
GROUP BY event_type;

-- Processing rate (last hour)
SELECT DATE_TRUNC('minute', processed_at) as minute,
       COUNT(*) as processed_count
FROM outbox
WHERE processed_at > NOW() - INTERVAL '1 hour'
GROUP BY minute
ORDER BY minute;

-- Average processing time
SELECT event_type,
       AVG(EXTRACT(EPOCH FROM (processed_at - created_at))) as avg_seconds
FROM outbox
WHERE processed_at IS NOT NULL
GROUP BY event_type;

-- Queue depth over time
SELECT
    DATE_TRUNC('hour', created_at) as hour,
    COUNT(*) as events_created,
    COUNT(processed_at) as events_processed,
    COUNT(*) - COUNT(processed_at) as queue_depth
FROM outbox
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour;

-- Error rate monitoring
SELECT
    DATE_TRUNC('hour', created_at) as hour,
    COUNT(*) as total_events,
    COUNT(CASE WHEN processed_at IS NULL AND created_at < NOW() - INTERVAL '5 minutes' THEN 1 END) as failed_events,
    ROUND(
        (COUNT(CASE WHEN processed_at IS NULL AND created_at < NOW() - INTERVAL '5 minutes' THEN 1 END) * 100.0) / COUNT(*),
        2
    ) as error_rate_percent
FROM outbox
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour;
```

#### ğŸ”” Alerting Thresholds

| Metric                | Warning     | Critical    | Action               |
| --------------------- | ----------- | ----------- | -------------------- |
| **Queue Depth**       | > 1,000     | > 5,000     | Scale pollers        |
| **Processing Rate**   | < 100/sec   | < 50/sec    | Check handlers       |
| **Error Rate**        | > 5%        | > 15%       | Investigation needed |
| **Memory Usage**      | > 80% limit | > 95% limit | Restart/scale        |
| **Restart Frequency** | > 5/hour    | > 20/hour   | Check memory leaks   |

### ğŸ› ï¸ Logging

The system uses structured logging with the following loggers:

- `plane.event_stream`: Main event stream operations
- `plane.event_stream.poller`: Outbox poller specific logs

Configure logging levels as needed:

```python
LOGGING = {
    'loggers': {
        'plane.event_stream': {
            'level': 'INFO',
            'handlers': ['console', 'file'],
        },
    },
}
```

## Performance Considerations

### ğŸ—„ï¸ Database Optimization

1. **Indexes**: Ensure proper indexes on the outbox table
2. **Partitioning**: Consider partitioning for high-volume scenarios
3. **Cleanup**: Regularly clean up old processed events

### ğŸ“ˆ Scaling

1. **ğŸ”„ Multiple Pollers**: Run multiple poller instances for higher throughput
2. **ğŸ“¦ Batch Sizes**: Tune batch sizes based on memory and latency requirements
3. **âš¡ Handler Optimization**: Optimize handlers for minimal memory usage and fast processing

### ğŸ’¡ Best Practices

1. **ğŸ” Idempotent Handlers**: Ensure handlers can be safely retried
2. **âŒ Error Handling**: Implement proper error handling and logging
3. **ğŸ§¹ Resource Cleanup**: Always clean up resources in handlers
4. **ğŸ“Š Monitoring**: Implement comprehensive monitoring and alerting

---

## ğŸ“š Additional Resources

- ğŸ“– [Event Stream Specification](../../../EVENT_STREAM_SPECIFICATION.md) - Detailed event schemas and processing requirements
- ğŸ˜ [PostgreSQL Triggers Documentation](https://www.postgresql.org/docs/current/sql-createtrigger.html) - Official PostgreSQL trigger documentation
- âš¡ [Async Python Guide](https://docs.python.org/3/library/asyncio.html) - Python asyncio documentation
- ğŸ”§ [psycopg3 Documentation](https://www.psycopg.org/psycopg3/docs/) - Async PostgreSQL adapter

## ğŸ¤ Contributing

When contributing to the event stream system:

1. **ğŸ“ Add tests** for new event types and handlers
2. **ğŸ“Š Include performance benchmarks** for significant changes
3. **ğŸ“– Update documentation** including this README
4. **ğŸ” Test memory usage** with realistic workloads
5. **âš¡ Benchmark throughput** before and after changes
